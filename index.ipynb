{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PICASSO'S - BUT FOR BOOKS\n",
    "\n",
    "## Objective\n",
    "The main objective of this project is to create a Recommendation System - collaborative filtering recommendation system specifically - to create an array of interesting suggestions based on the user's input.\n",
    "\n",
    "* We could create a model that predicts your next read\n",
    "* Or predict your next author\n",
    "\n",
    "**Specific Objectives**\n",
    "* To investigate the Genres with the highest readership and popularity\n",
    "* To investigate the Publishers churning the highest number of books\n",
    "* To investigate the Authors with a lot of publications and popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "The data was sourced from Kaggle. \n",
    "\n",
    "There are 3 csv files containing the \n",
    "* Books Dataset\n",
    "* Users Dataset\n",
    "* Ratings Dataset\n",
    "\n",
    "The columns in the **Books Dataset** include:\n",
    "<ol>\n",
    "    <li>Book-Author</li>\n",
    "    <li>Book-Title</li>\n",
    "    <li>ISBN</li>\n",
    "    <li>Image-URL-L</li>\n",
    "    <li>Image-URL-M</li>\n",
    "    <li>Image-URL-S</li>\n",
    "    <li>Publisher</li>\n",
    "    <li>Year-Of-Publication</li>\n",
    "</ol>\n",
    "\n",
    "The columns in the **Users Dataset** are:\n",
    "<ol>\n",
    "    <li>Age</li>\n",
    "    <li>Location</li>\n",
    "    <li>User-ID</li>\n",
    "</ol>\n",
    "\n",
    "The columns in the **Ratings Dataset** are:\n",
    "<ol>\n",
    "    <li>Book-Rating</li>\n",
    "    <li>ISBN</li>\n",
    "    <li>User-ID</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scipy Sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Modelling\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Pickle\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataUnderstading:\n",
    "    def __init__(self, name, df='None'):\n",
    "        self.df = df\n",
    "        self.name = name\n",
    "        \n",
    "    def load_data(self, path):\n",
    "        if self.df == 'None':\n",
    "            self.df = pd.read_csv(path, sep=';', encoding='latin-1', on_bad_lines='skip', low_memory=False)\n",
    "            self.df.head()\n",
    "            \n",
    "        return self.df\n",
    "    \n",
    "    def understanding(self):\n",
    "        # Shape and Columns\n",
    "        print(f\"DATA UNDERSTANDING OF THE {self.name} Dataset\")\n",
    "        print(\"\\n\\nSHAPE\")\n",
    "        print(f\"The {self.name} dataset contains {self.df.shape[0]:,} records and {self.df.shape[1]} columns\")\n",
    "        print(f\"The columns are { [str(col) for col in sorted(self.df.columns)] }\")\n",
    "        \n",
    "        # Missing values \n",
    "        print(\"\\n\\nMISSING VALUES\")\n",
    "        print(f\"\\nMissing values in the {self.name} dataset:\")\n",
    "        print(f\"{self.df.isnull().sum().sum()}\")\n",
    "        \n",
    "        if self.df.isnull().sum().sum() > 0:\n",
    "            print(\"\\nA deeper analysis of missing values\")\n",
    "            for feature, val in self.df.isnull().sum().items():\n",
    "                if val > 0:\n",
    "                    print(f\"{feature} has {val} missing values\")\n",
    "        \n",
    "        # Missing values \n",
    "        print(\"\\n\\nDUPLICATES\")\n",
    "        print(f\"\\nDuplicate values in the {self.name} dataset:\")\n",
    "        print(f\"{self.df[self.df.duplicated()].sum().sum()}\")\n",
    "        \n",
    "        # Data Types\n",
    "        data_types = {}\n",
    "        for dt in self.df.dtypes:\n",
    "            if dt not in data_types:\n",
    "                data_types[dt] = 1\n",
    "            else:\n",
    "                data_types[dt] += 1\n",
    "                \n",
    "        print(\"\\n\\nDATATYPES\")\n",
    "        print(f\"\\nNumber of Features with {[dt for dt in list(data_types.keys())]} datatypes \"\\\n",
    "          +f\"are {[dt for dt in list(data_types.values())]} respectively\")\n",
    "        \n",
    "        # Unique Values\n",
    "        print(\"\\n\\nUNIQUE VALUES\")\n",
    "        for col in self.df.columns:\n",
    "            print(f\"\\nNumber of unique values in {col} are {self.df[col].nunique()}\")\n",
    "            \n",
    "            print(f\"\\nSome unique values in the {col} column:\")\n",
    "            if self.df[col].nunique() > 11:\n",
    "                print(self.df[col].unique()[:5])\n",
    "            else:\n",
    "                print(self.df[col].unique())\n",
    "                \n",
    "            print(f\"\\nTop 10 Sample of the Distribution of the {col} column\")\n",
    "            print(self.df[col].value_counts()[:10])\n",
    "            \n",
    "        \n",
    "        # Numerical Columns\n",
    "        print(\"\\n\\nCOLUMNS\")\n",
    "        print(\"\\nThe Numerical Features are:\")\n",
    "        numerical_features = [col for col in self.df.select_dtypes(exclude='O')]\n",
    "        if len(numerical_features) > 0:\n",
    "            print(f\"{ [col for col in numerical_features] }\")\n",
    "        else:\n",
    "            print('None')\n",
    "            \n",
    "                \n",
    "        # Categorical Columns\n",
    "        print(\"\\nThe Categorical Features are:\")\n",
    "        cat_features = [col for col in self.df.select_dtypes(include='O')]\n",
    "        if len(cat_features) > 0:\n",
    "            print(f\"{ [col for col in cat_features] }\")\n",
    "        else:\n",
    "            print('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATASET 1 - Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                         Book-Title  \\\n",
       "0  0195153448                                Classical Mythology   \n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4  0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "            Book-Author Year-Of-Publication                   Publisher  \\\n",
       "0    Mark P. O. Morford                2002     Oxford University Press   \n",
       "1  Richard Bruce Wright                2001       HarperFlamingo Canada   \n",
       "2          Carlo D'Este                1991             HarperPerennial   \n",
       "3      Gina Bari Kolata                1999        Farrar Straus Giroux   \n",
       "4       E. J. W. Barber                1999  W. W. Norton &amp; Company   \n",
       "\n",
       "                                         Image-URL-S  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-L  \n",
       "0  http://images.amazon.com/images/P/0195153448.0...  \n",
       "1  http://images.amazon.com/images/P/0002005018.0...  \n",
       "2  http://images.amazon.com/images/P/0060973129.0...  \n",
       "3  http://images.amazon.com/images/P/0374157065.0...  \n",
       "4  http://images.amazon.com/images/P/0393045218.0...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = DataUnderstading(name='Books')\n",
    "books_df = books.load_data(path='./data/BX-Books.csv')\n",
    "books_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA UNDERSTANDING OF THE Books Dataset\n",
      "\n",
      "\n",
      "SHAPE\n",
      "The Books dataset contains 271,360 records and 8 columns\n",
      "The columns are ['Book-Author', 'Book-Title', 'ISBN', 'Image-URL-L', 'Image-URL-M', 'Image-URL-S', 'Publisher', 'Year-Of-Publication']\n",
      "\n",
      "\n",
      "MISSING VALUES\n",
      "\n",
      "Missing values in the Books dataset:\n",
      "7\n",
      "\n",
      "A deeper analysis of missing values\n",
      "Book-Author has 2 missing values\n",
      "Publisher has 2 missing values\n",
      "Image-URL-L has 3 missing values\n",
      "\n",
      "\n",
      "DUPLICATES\n",
      "\n",
      "Duplicate values in the Books dataset:\n",
      "0\n",
      "\n",
      "\n",
      "DATATYPES\n",
      "\n",
      "Number of Features with [dtype('O')] datatypes are [8] respectively\n",
      "\n",
      "\n",
      "UNIQUE VALUES\n",
      "\n",
      "Number of unique values in ISBN are 271360\n",
      "\n",
      "Some unique values in the ISBN column:\n",
      "['0195153448' '0002005018' '0060973129' '0374157065' '0393045218']\n",
      "\n",
      "Top 10 Sample of the Distribution of the ISBN column\n",
      "ISBN\n",
      "0195153448    1\n",
      "0746008481    1\n",
      "0395219906    1\n",
      "043916169X    1\n",
      "0879235322    1\n",
      "077108482X    1\n",
      "0207124310    1\n",
      "0439172543    1\n",
      "0590408518    1\n",
      "0902375512    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in Book-Title are 242135\n",
      "\n",
      "Some unique values in the Book-Title column:\n",
      "['Classical Mythology' 'Clara Callan' 'Decision in Normandy'\n",
      " 'Flu: The Story of the Great Influenza Pandemic of 1918 and the Search for the Virus That Caused It'\n",
      " 'The Mummies of Urumchi']\n",
      "\n",
      "Top 10 Sample of the Distribution of the Book-Title column\n",
      "Book-Title\n",
      "Selected Poems                    27\n",
      "Little Women                      24\n",
      "Wuthering Heights                 21\n",
      "The Secret Garden                 20\n",
      "Dracula                           20\n",
      "Adventures of Huckleberry Finn    20\n",
      "Jane Eyre                         19\n",
      "The Night Before Christmas        18\n",
      "Pride and Prejudice               18\n",
      "Great Expectations                17\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in Book-Author are 102022\n",
      "\n",
      "Some unique values in the Book-Author column:\n",
      "['Mark P. O. Morford' 'Richard Bruce Wright' \"Carlo D'Este\"\n",
      " 'Gina Bari Kolata' 'E. J. W. Barber']\n",
      "\n",
      "Top 10 Sample of the Distribution of the Book-Author column\n",
      "Book-Author\n",
      "Agatha Christie        632\n",
      "William Shakespeare    567\n",
      "Stephen King           524\n",
      "Ann M. Martin          423\n",
      "Carolyn Keene          373\n",
      "Francine Pascal        372\n",
      "Isaac Asimov           330\n",
      "Nora Roberts           315\n",
      "Barbara Cartland       307\n",
      "Charles Dickens        302\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in Year-Of-Publication are 118\n",
      "\n",
      "Some unique values in the Year-Of-Publication column:\n",
      "['2002' '2001' '1991' '1999' '2000']\n",
      "\n",
      "Top 10 Sample of the Distribution of the Year-Of-Publication column\n",
      "Year-Of-Publication\n",
      "2002    17627\n",
      "1999    17431\n",
      "2001    17359\n",
      "2000    17232\n",
      "1998    15766\n",
      "1997    14890\n",
      "2003    14358\n",
      "1996    14030\n",
      "1995    13546\n",
      "1994    11796\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in Publisher are 16807\n",
      "\n",
      "Some unique values in the Publisher column:\n",
      "['Oxford University Press' 'HarperFlamingo Canada' 'HarperPerennial'\n",
      " 'Farrar Straus Giroux' 'W. W. Norton &amp; Company']\n",
      "\n",
      "Top 10 Sample of the Distribution of the Publisher column\n",
      "Publisher\n",
      "Harlequin                   7535\n",
      "Silhouette                  4220\n",
      "Pocket                      3905\n",
      "Ballantine Books            3783\n",
      "Bantam Books                3646\n",
      "Scholastic                  3160\n",
      "Simon &amp; Schuster        2971\n",
      "Penguin Books               2844\n",
      "Berkley Publishing Group    2771\n",
      "Warner Books                2727\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in Image-URL-S are 271044\n",
      "\n",
      "Some unique values in the Image-URL-S column:\n",
      "['http://images.amazon.com/images/P/0195153448.01.THUMBZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/0002005018.01.THUMBZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/0060973129.01.THUMBZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/0374157065.01.THUMBZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/0393045218.01.THUMBZZZ.jpg']\n",
      "\n",
      "Top 10 Sample of the Distribution of the Image-URL-S column\n",
      "Image-URL-S\n",
      "http://images.amazon.com/images/P/185326119X.01.THUMBZZZ.jpg    2\n",
      "http://images.amazon.com/images/P/006099486X.01.THUMBZZZ.jpg    2\n",
      "http://images.amazon.com/images/P/044991089X.01.THUMBZZZ.jpg    2\n",
      "http://images.amazon.com/images/P/086611873X.01.THUMBZZZ.jpg    2\n",
      "http://images.amazon.com/images/P/039552105X.01.THUMBZZZ.jpg    2\n",
      "http://images.amazon.com/images/P/038531700X.01.THUMBZZZ.jpg    2\n",
      "http://images.amazon.com/images/P/067103619X.01.THUMBZZZ.jpg    2\n",
      "http://images.amazon.com/images/P/156947012X.01.THUMBZZZ.jpg    2\n",
      "http://images.amazon.com/images/P/096788330X.01.THUMBZZZ.jpg    2\n",
      "http://images.amazon.com/images/P/006039384X.01.THUMBZZZ.jpg    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in Image-URL-M are 271044\n",
      "\n",
      "Some unique values in the Image-URL-M column:\n",
      "['http://images.amazon.com/images/P/0195153448.01.MZZZZZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/0002005018.01.MZZZZZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/0060973129.01.MZZZZZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/0374157065.01.MZZZZZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/0393045218.01.MZZZZZZZ.jpg']\n",
      "\n",
      "Top 10 Sample of the Distribution of the Image-URL-M column\n",
      "Image-URL-M\n",
      "http://images.amazon.com/images/P/185326119X.01.MZZZZZZZ.jpg    2\n",
      "http://images.amazon.com/images/P/006099486X.01.MZZZZZZZ.jpg    2\n",
      "http://images.amazon.com/images/P/044991089X.01.MZZZZZZZ.jpg    2\n",
      "http://images.amazon.com/images/P/086611873X.01.MZZZZZZZ.jpg    2\n",
      "http://images.amazon.com/images/P/039552105X.01.MZZZZZZZ.jpg    2\n",
      "http://images.amazon.com/images/P/038531700X.01.MZZZZZZZ.jpg    2\n",
      "http://images.amazon.com/images/P/067103619X.01.MZZZZZZZ.jpg    2\n",
      "http://images.amazon.com/images/P/156947012X.01.MZZZZZZZ.jpg    2\n",
      "http://images.amazon.com/images/P/096788330X.01.MZZZZZZZ.jpg    2\n",
      "http://images.amazon.com/images/P/006039384X.01.MZZZZZZZ.jpg    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in Image-URL-L are 271041\n",
      "\n",
      "Some unique values in the Image-URL-L column:\n",
      "['http://images.amazon.com/images/P/0195153448.01.LZZZZZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/0002005018.01.LZZZZZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/0060973129.01.LZZZZZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/0374157065.01.LZZZZZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/0393045218.01.LZZZZZZZ.jpg']\n",
      "\n",
      "Top 10 Sample of the Distribution of the Image-URL-L column\n",
      "Image-URL-L\n",
      "http://images.amazon.com/images/P/225307649X.01.LZZZZZZZ.jpg    2\n",
      "http://images.amazon.com/images/P/044021145X.01.LZZZZZZZ.jpg    2\n",
      "http://images.amazon.com/images/P/044991089X.01.LZZZZZZZ.jpg    2\n",
      "http://images.amazon.com/images/P/039552105X.01.LZZZZZZZ.jpg    2\n",
      "http://images.amazon.com/images/P/014062063X.01.LZZZZZZZ.jpg    2\n",
      "http://images.amazon.com/images/P/086611873X.01.LZZZZZZZ.jpg    2\n",
      "http://images.amazon.com/images/P/038531700X.01.LZZZZZZZ.jpg    2\n",
      "http://images.amazon.com/images/P/067103619X.01.LZZZZZZZ.jpg    2\n",
      "http://images.amazon.com/images/P/156947012X.01.LZZZZZZZ.jpg    2\n",
      "http://images.amazon.com/images/P/096788330X.01.LZZZZZZZ.jpg    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "COLUMNS\n",
      "\n",
      "The Numerical Features are:\n",
      "None\n",
      "\n",
      "The Categorical Features are:\n",
      "['ISBN', 'Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher', 'Image-URL-S', 'Image-URL-M', 'Image-URL-L']\n"
     ]
    }
   ],
   "source": [
    "books.understanding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATASET 2 - Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>nyc, new york, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>stockton, california, usa</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>moscow, yukon territory, russia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>porto, v.n.gaia, portugal</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>farnborough, hants, united kingdom</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID                            Location   Age\n",
       "0        1                  nyc, new york, usa   NaN\n",
       "1        2           stockton, california, usa  18.0\n",
       "2        3     moscow, yukon territory, russia   NaN\n",
       "3        4           porto, v.n.gaia, portugal  17.0\n",
       "4        5  farnborough, hants, united kingdom   NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = DataUnderstading(name='Users')\n",
    "users_df = users.load_data(path='./data/BX-Users.csv')\n",
    "users_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA UNDERSTANDING OF THE Users Dataset\n",
      "\n",
      "\n",
      "SHAPE\n",
      "The Users dataset contains 278,858 records and 3 columns\n",
      "The columns are ['Age', 'Location', 'User-ID']\n",
      "\n",
      "\n",
      "MISSING VALUES\n",
      "\n",
      "Missing values in the Users dataset:\n",
      "110762\n",
      "\n",
      "A deeper analysis of missing values\n",
      "Age has 110762 missing values\n",
      "\n",
      "\n",
      "DUPLICATES\n",
      "\n",
      "Duplicate values in the Users dataset:\n",
      "0.0\n",
      "\n",
      "\n",
      "DATATYPES\n",
      "\n",
      "Number of Features with [dtype('int64'), dtype('O'), dtype('float64')] datatypes are [1, 1, 1] respectively\n",
      "\n",
      "\n",
      "UNIQUE VALUES\n",
      "\n",
      "Number of unique values in User-ID are 278858\n",
      "\n",
      "Some unique values in the User-ID column:\n",
      "[1 2 3 4 5]\n",
      "\n",
      "Top 10 Sample of the Distribution of the User-ID column\n",
      "User-ID\n",
      "1         1\n",
      "185904    1\n",
      "185910    1\n",
      "185909    1\n",
      "185908    1\n",
      "185907    1\n",
      "185906    1\n",
      "185905    1\n",
      "185903    1\n",
      "185725    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in Location are 57339\n",
      "\n",
      "Some unique values in the Location column:\n",
      "['nyc, new york, usa' 'stockton, california, usa'\n",
      " 'moscow, yukon territory, russia' 'porto, v.n.gaia, portugal'\n",
      " 'farnborough, hants, united kingdom']\n",
      "\n",
      "Top 10 Sample of the Distribution of the Location column\n",
      "Location\n",
      "london, england, united kingdom        2506\n",
      "toronto, ontario, canada               2250\n",
      "sydney, new south wales, australia     1744\n",
      "melbourne, victoria, australia         1708\n",
      "portland, oregon, usa                  1629\n",
      "chicago, illinois, usa                 1526\n",
      "seattle, washington, usa               1484\n",
      "new york, new york, usa                1411\n",
      "madrid, madrid, spain                  1400\n",
      "vancouver, british columbia, canada    1359\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in Age are 165\n",
      "\n",
      "Some unique values in the Age column:\n",
      "[nan 18. 17. 61. 26.]\n",
      "\n",
      "Top 10 Sample of the Distribution of the Age column\n",
      "Age\n",
      "24.0    5687\n",
      "25.0    5618\n",
      "26.0    5547\n",
      "23.0    5456\n",
      "27.0    5383\n",
      "        ... \n",
      "11.0     121\n",
      "75.0     119\n",
      "76.0     114\n",
      "2.0      105\n",
      "10.0      84\n",
      "Name: count, Length: 71, dtype: int64\n",
      "\n",
      "\n",
      "COLUMNS\n",
      "\n",
      "The Numerical Features are:\n",
      "['User-ID', 'Age']\n",
      "\n",
      "The Categorical Features are:\n",
      "['Location']\n"
     ]
    }
   ],
   "source": [
    "users.understanding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATASET 3 - Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID        ISBN  Book-Rating\n",
       "0   276725  034545104X            0\n",
       "1   276726  0155061224            5\n",
       "2   276727  0446520802            0\n",
       "3   276729  052165615X            3\n",
       "4   276729  0521795028            6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = DataUnderstading(name='Rating')\n",
    "ratings_df = rating.load_data(path='./data/BX-Book-Ratings.csv')\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA UNDERSTANDING OF THE Rating Dataset\n",
      "\n",
      "\n",
      "SHAPE\n",
      "The Rating dataset contains 1,149,780 records and 3 columns\n",
      "The columns are ['Book-Rating', 'ISBN', 'User-ID']\n",
      "\n",
      "\n",
      "MISSING VALUES\n",
      "\n",
      "Missing values in the Rating dataset:\n",
      "0\n",
      "\n",
      "\n",
      "DUPLICATES\n",
      "\n",
      "Duplicate values in the Rating dataset:\n",
      "0\n",
      "\n",
      "\n",
      "DATATYPES\n",
      "\n",
      "Number of Features with [dtype('int64'), dtype('O')] datatypes are [2, 1] respectively\n",
      "\n",
      "\n",
      "UNIQUE VALUES\n",
      "\n",
      "Number of unique values in User-ID are 105283\n",
      "\n",
      "Some unique values in the User-ID column:\n",
      "[276725 276726 276727 276729 276733]\n",
      "\n",
      "Top 10 Sample of the Distribution of the User-ID column\n",
      "User-ID\n",
      "11676     13602\n",
      "198711     7550\n",
      "153662     6109\n",
      "98391      5891\n",
      "35859      5850\n",
      "212898     4785\n",
      "278418     4533\n",
      "76352      3367\n",
      "110973     3100\n",
      "235105     3067\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in ISBN are 340556\n",
      "\n",
      "Some unique values in the ISBN column:\n",
      "['034545104X' '0155061224' '0446520802' '052165615X' '0521795028']\n",
      "\n",
      "Top 10 Sample of the Distribution of the ISBN column\n",
      "ISBN\n",
      "0971880107    2502\n",
      "0316666343    1295\n",
      "0385504209     883\n",
      "0060928336     732\n",
      "0312195516     723\n",
      "044023722X     647\n",
      "0679781587     639\n",
      "0142001740     615\n",
      "067976402X     614\n",
      "0671027360     586\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in Book-Rating are 11\n",
      "\n",
      "Some unique values in the Book-Rating column:\n",
      "[ 0  5  3  6  8  7 10  9  4  1  2]\n",
      "\n",
      "Top 10 Sample of the Distribution of the Book-Rating column\n",
      "Book-Rating\n",
      "0     716109\n",
      "8     103736\n",
      "10     78610\n",
      "7      76457\n",
      "9      67541\n",
      "5      50974\n",
      "6      36924\n",
      "4       8904\n",
      "3       5996\n",
      "2       2759\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "COLUMNS\n",
      "\n",
      "The Numerical Features are:\n",
      "['User-ID', 'Book-Rating']\n",
      "\n",
      "The Categorical Features are:\n",
      "['ISBN']\n"
     ]
    }
   ],
   "source": [
    "rating.understanding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,149,780\n"
     ]
    }
   ],
   "source": [
    "print(f'{1149780:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "**Validity**: \n",
    "\n",
    "Here we would make sure that the data fits into the correct range and format\n",
    "Like we would \n",
    "- remove irrelevant columns, \n",
    "- remove white space, \n",
    "- typos in our variables.\n",
    "- change data types say date to date_time.\n",
    "\n",
    "\n",
    "**Accuracy** : \n",
    "\n",
    "Here data should represent the real world\n",
    "Like a child can't be married or if we have a dataset about the cost of living in cities the total column must be equivalent to the sum of rent, transport, and food\n",
    "\n",
    "**Completeness** : \n",
    "\n",
    "Here you check if all required data is present\n",
    "You would check for missing values and deal with the missing values\n",
    "\n",
    "**Consistency**: \n",
    "\n",
    "Make sure that the data is aligned.\n",
    "Hapa ndio tutacheck duplicates,\n",
    "\n",
    "**Uniformity**\n",
    "\n",
    "Here data is standardized.\n",
    "eg fixing messy column names,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validity\n",
    "\n",
    "#### Change column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns in the books_df\n",
    "books_df.rename(columns={\n",
    "    'Book-Title': 'title',\n",
    "    'Book-Author': 'author',\n",
    "    'Year-Of-Publication': 'year',\n",
    "    'Publisher': 'publisher',\n",
    "    'Image-URL-L':'img_url',\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ISBN', 'title', 'author', 'year', 'publisher', 'Image-URL-S',\n",
       "       'Image-URL-M', 'img_url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check\n",
    "books_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'Location', 'Age'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename columns in the users_df\n",
    "users_df.rename(columns={\n",
    "    'User-ID': 'user_id',\n",
    "}, inplace=True)\n",
    "\n",
    "# Check\n",
    "users_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'ISBN', 'rating'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename columns in the ratings_df\n",
    "ratings_df.rename(columns={\n",
    "    'User-ID': 'user_id',\n",
    "    'Book-Rating': 'rating',\n",
    "}, inplace=True)\n",
    "\n",
    "# Check\n",
    "ratings_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ISBN           0\n",
       "title          0\n",
       "author         0\n",
       "year           0\n",
       "publisher      0\n",
       "Image-URL-S    0\n",
       "Image-URL-M    0\n",
       "img_url        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop any records in the books and ratings df\n",
    "books_df.dropna(axis=0, inplace=True)\n",
    "\n",
    "# Confirm if there are any missing values now\n",
    "books_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id     0\n",
       "Location    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the 'age' feature in the users df\n",
    "users_df.drop('Age', axis=1, inplace=True)\n",
    "\n",
    "# Confirm if there are any missing values now\n",
    "users_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistency\n",
    "\n",
    "#### Maintain only top 200 contributing members in the ratings dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([ 11676, 198711, 153662,  98391,  35859, 212898, 278418,  76352, 110973,\n",
       "       235105,\n",
       "       ...\n",
       "       260183,  73681,  44296, 155916,   9856, 274808,  28634,  59727, 268622,\n",
       "       188951],\n",
       "      dtype='int64', name='user_id', length=899)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over_200_contribution = ratings_df['user_id'].value_counts() > 200\n",
    "over_200_contribution = over_200_contribution[over_200_contribution == True].index\n",
    "over_200_contribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observation\n",
    "> Only 899 contributors have rated more that 200 books in the ratings dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA UNDERSTANDING OF THE New Ratings Dataset\n",
      "\n",
      "\n",
      "SHAPE\n",
      "The New Ratings dataset contains 526,356 records and 3 columns\n",
      "The columns are ['ISBN', 'rating', 'user_id']\n",
      "\n",
      "\n",
      "MISSING VALUES\n",
      "\n",
      "Missing values in the New Ratings dataset:\n",
      "0\n",
      "\n",
      "\n",
      "DUPLICATES\n",
      "\n",
      "Duplicate values in the New Ratings dataset:\n",
      "0\n",
      "\n",
      "\n",
      "DATATYPES\n",
      "\n",
      "Number of Features with [dtype('int64'), dtype('O')] datatypes are [2, 1] respectively\n",
      "\n",
      "\n",
      "UNIQUE VALUES\n",
      "\n",
      "Number of unique values in user_id are 899\n",
      "\n",
      "Some unique values in the user_id column:\n",
      "[277427 277478 277639 278418    254]\n",
      "\n",
      "Top 10 Sample of the Distribution of the user_id column\n",
      "user_id\n",
      "11676     13602\n",
      "198711     7550\n",
      "153662     6109\n",
      "98391      5891\n",
      "35859      5850\n",
      "212898     4785\n",
      "278418     4533\n",
      "76352      3367\n",
      "110973     3100\n",
      "235105     3067\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in ISBN are 207291\n",
      "\n",
      "Some unique values in the ISBN column:\n",
      "['002542730X' '0026217457' '003008685X' '0030615321' '0060002050']\n",
      "\n",
      "Top 10 Sample of the Distribution of the ISBN column\n",
      "ISBN\n",
      "0971880107    363\n",
      "0316666343    270\n",
      "0060928336    220\n",
      "0440214041    218\n",
      "0385504209    215\n",
      "044021145X    204\n",
      "0440211727    203\n",
      "067976402X    193\n",
      "0446672211    183\n",
      "059035342X    183\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in rating are 11\n",
      "\n",
      "Some unique values in the rating column:\n",
      "[10  0  8  7  9  6  5  4  3  2  1]\n",
      "\n",
      "Top 10 Sample of the Distribution of the rating column\n",
      "rating\n",
      "0     393354\n",
      "8      31453\n",
      "10     28131\n",
      "9      23407\n",
      "7      21041\n",
      "5      15848\n",
      "6       9026\n",
      "4       1777\n",
      "3       1146\n",
      "2        632\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "COLUMNS\n",
      "\n",
      "The Numerical Features are:\n",
      "['user_id', 'rating']\n",
      "\n",
      "The Categorical Features are:\n",
      "['ISBN']\n"
     ]
    }
   ],
   "source": [
    "# Create a new dataframe composed of these individuals\n",
    "ratings_df = ratings_df[ratings_df['user_id'].isin(over_200_contribution)]\n",
    "\n",
    "# Confirm changes have worked\n",
    "new_ratings = DataUnderstading(name='New Ratings', df=ratings_df)\n",
    "new_ratings.understanding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging the data - Ratings and Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching column between the ratings and books is\n",
      "ISBN\n"
     ]
    }
   ],
   "source": [
    "# Confirming the common column between two dataframes\n",
    "def similar_cols(df1, name1, df2, name2):\n",
    "    print(f\"Matching column between the {name1} and {name2} is\")\n",
    "\n",
    "    for col in df1.columns:\n",
    "        if col in df2.columns:\n",
    "            print(col)\n",
    "            break\n",
    "\n",
    "# Similar columns between the ratings and the books dataframes\n",
    "similar_cols(ratings_df, \"ratings\", books_df, 'books')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>img_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>277427</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>10</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "      <td>James Finn Garner</td>\n",
       "      <td>1994</td>\n",
       "      <td>John Wiley &amp;amp; Sons Inc</td>\n",
       "      <td>http://images.amazon.com/images/P/002542730X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/002542730X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/002542730X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3363</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>0</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "      <td>James Finn Garner</td>\n",
       "      <td>1994</td>\n",
       "      <td>John Wiley &amp;amp; Sons Inc</td>\n",
       "      <td>http://images.amazon.com/images/P/002542730X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/002542730X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/002542730X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11676</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>6</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "      <td>James Finn Garner</td>\n",
       "      <td>1994</td>\n",
       "      <td>John Wiley &amp;amp; Sons Inc</td>\n",
       "      <td>http://images.amazon.com/images/P/002542730X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/002542730X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/002542730X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12538</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>10</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "      <td>James Finn Garner</td>\n",
       "      <td>1994</td>\n",
       "      <td>John Wiley &amp;amp; Sons Inc</td>\n",
       "      <td>http://images.amazon.com/images/P/002542730X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/002542730X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/002542730X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13552</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>0</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "      <td>James Finn Garner</td>\n",
       "      <td>1994</td>\n",
       "      <td>John Wiley &amp;amp; Sons Inc</td>\n",
       "      <td>http://images.amazon.com/images/P/002542730X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/002542730X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/002542730X.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id        ISBN  rating  \\\n",
       "0   277427  002542730X      10   \n",
       "1     3363  002542730X       0   \n",
       "2    11676  002542730X       6   \n",
       "3    12538  002542730X      10   \n",
       "4    13552  002542730X       0   \n",
       "\n",
       "                                               title             author  year  \\\n",
       "0  Politically Correct Bedtime Stories: Modern Ta...  James Finn Garner  1994   \n",
       "1  Politically Correct Bedtime Stories: Modern Ta...  James Finn Garner  1994   \n",
       "2  Politically Correct Bedtime Stories: Modern Ta...  James Finn Garner  1994   \n",
       "3  Politically Correct Bedtime Stories: Modern Ta...  James Finn Garner  1994   \n",
       "4  Politically Correct Bedtime Stories: Modern Ta...  James Finn Garner  1994   \n",
       "\n",
       "                   publisher  \\\n",
       "0  John Wiley &amp; Sons Inc   \n",
       "1  John Wiley &amp; Sons Inc   \n",
       "2  John Wiley &amp; Sons Inc   \n",
       "3  John Wiley &amp; Sons Inc   \n",
       "4  John Wiley &amp; Sons Inc   \n",
       "\n",
       "                                         Image-URL-S  \\\n",
       "0  http://images.amazon.com/images/P/002542730X.0...   \n",
       "1  http://images.amazon.com/images/P/002542730X.0...   \n",
       "2  http://images.amazon.com/images/P/002542730X.0...   \n",
       "3  http://images.amazon.com/images/P/002542730X.0...   \n",
       "4  http://images.amazon.com/images/P/002542730X.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "0  http://images.amazon.com/images/P/002542730X.0...   \n",
       "1  http://images.amazon.com/images/P/002542730X.0...   \n",
       "2  http://images.amazon.com/images/P/002542730X.0...   \n",
       "3  http://images.amazon.com/images/P/002542730X.0...   \n",
       "4  http://images.amazon.com/images/P/002542730X.0...   \n",
       "\n",
       "                                             img_url  \n",
       "0  http://images.amazon.com/images/P/002542730X.0...  \n",
       "1  http://images.amazon.com/images/P/002542730X.0...  \n",
       "2  http://images.amazon.com/images/P/002542730X.0...  \n",
       "3  http://images.amazon.com/images/P/002542730X.0...  \n",
       "4  http://images.amazon.com/images/P/002542730X.0...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging the ratings with the books dataset\n",
    "ratings_with_books = ratings_df.merge(right=books_df, on='ISBN')\n",
    "ratings_with_books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA UNDERSTANDING OF THE Merged Ratings and Books Dataset\n",
      "\n",
      "\n",
      "SHAPE\n",
      "The Merged Ratings and Books dataset contains 487,665 records and 10 columns\n",
      "The columns are ['ISBN', 'Image-URL-M', 'Image-URL-S', 'author', 'img_url', 'publisher', 'rating', 'title', 'user_id', 'year']\n",
      "\n",
      "\n",
      "MISSING VALUES\n",
      "\n",
      "Missing values in the Merged Ratings and Books dataset:\n",
      "0\n",
      "\n",
      "\n",
      "DUPLICATES\n",
      "\n",
      "Duplicate values in the Merged Ratings and Books dataset:\n",
      "0\n",
      "\n",
      "\n",
      "DATATYPES\n",
      "\n",
      "Number of Features with [dtype('int64'), dtype('O')] datatypes are [2, 8] respectively\n",
      "\n",
      "\n",
      "UNIQUE VALUES\n",
      "\n",
      "Number of unique values in user_id are 899\n",
      "\n",
      "Some unique values in the user_id column:\n",
      "[277427   3363  11676  12538  13552]\n",
      "\n",
      "Top 10 Sample of the Distribution of the user_id column\n",
      "user_id\n",
      "11676     11144\n",
      "198711     6456\n",
      "153662     5814\n",
      "98391      5777\n",
      "35859      5646\n",
      "212898     4289\n",
      "278418     3996\n",
      "76352      3329\n",
      "110973     2971\n",
      "235105     2943\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in ISBN are 178012\n",
      "\n",
      "Some unique values in the ISBN column:\n",
      "['002542730X' '0026217457' '003008685X' '0030615321' '0060002050']\n",
      "\n",
      "Top 10 Sample of the Distribution of the ISBN column\n",
      "ISBN\n",
      "0971880107    363\n",
      "0316666343    270\n",
      "0060928336    220\n",
      "0440214041    218\n",
      "0385504209    215\n",
      "044021145X    204\n",
      "0440211727    203\n",
      "067976402X    193\n",
      "059035342X    183\n",
      "0446672211    183\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in rating are 11\n",
      "\n",
      "Some unique values in the rating column:\n",
      "[10  0  6  7  5  8  9  4  3  1  2]\n",
      "\n",
      "Top 10 Sample of the Distribution of the rating column\n",
      "rating\n",
      "0     366406\n",
      "8      28529\n",
      "10     26267\n",
      "9      21574\n",
      "7      18611\n",
      "5      14695\n",
      "6       7968\n",
      "4       1577\n",
      "3       1020\n",
      "2        556\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in title are 160264\n",
      "\n",
      "Some unique values in the title column:\n",
      "['Politically Correct Bedtime Stories: Modern Tales for Our Life and Times'\n",
      " 'Vegetarian Times Complete Cookbook' 'Pioneers'\n",
      " 'Ask for May, Settle for June (A Doonesbury book)'\n",
      " 'On a Wicked Dawn (Cynster Novels)']\n",
      "\n",
      "Top 10 Sample of the Distribution of the title column\n",
      "title\n",
      "Wild Animus                                        363\n",
      "Bridget Jones's Diary                              277\n",
      "The Lovely Bones: A Novel                          270\n",
      "The Notebook                                       241\n",
      "The Pelican Brief                                  236\n",
      "The Nanny Diaries: A Novel                         230\n",
      "A Painted House                                    228\n",
      "Divine Secrets of the Ya-Ya Sisterhood: A Novel    228\n",
      "The Firm                                           227\n",
      "The Da Vinci Code                                  224\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in author are 67161\n",
      "\n",
      "Some unique values in the author column:\n",
      "['James Finn Garner' 'Lucy  Moll' 'James Fenimore Cooper' 'G. B. Trudeau'\n",
      " 'Stephanie Laurens']\n",
      "\n",
      "Top 10 Sample of the Distribution of the author column\n",
      "author\n",
      "Nora Roberts          4258\n",
      "Stephen King          4036\n",
      "James Patterson       2195\n",
      "Mary Higgins Clark    2080\n",
      "Danielle Steel        1958\n",
      "John Grisham          1909\n",
      "Dean R. Koontz        1858\n",
      "V.C. Andrews          1635\n",
      "Sue Grafton           1572\n",
      "Tom Clancy            1561\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in year are 102\n",
      "\n",
      "Some unique values in the year column:\n",
      "['1994' '1995' '1974' '1982' '2002']\n",
      "\n",
      "Top 10 Sample of the Distribution of the year column\n",
      "year\n",
      "2002    38502\n",
      "2001    34421\n",
      "1999    33328\n",
      "2003    32650\n",
      "2000    31431\n",
      "1998    28746\n",
      "1996    28294\n",
      "1997    27753\n",
      "1995    26217\n",
      "1994    22701\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in publisher are 11005\n",
      "\n",
      "Some unique values in the publisher column:\n",
      "['John Wiley &amp; Sons Inc' 'John Wiley &amp; Sons' 'Thomson Learning'\n",
      " 'Henry Holt &amp; Co' 'Avon Books']\n",
      "\n",
      "Top 10 Sample of the Distribution of the publisher column\n",
      "publisher\n",
      "Harlequin                   18441\n",
      "Pocket                      16425\n",
      "Ballantine Books            15505\n",
      "Berkley Publishing Group    13919\n",
      "Bantam Books                12256\n",
      "Warner Books                11827\n",
      "Silhouette                  10332\n",
      "Avon                         9980\n",
      "Signet Book                  9394\n",
      "Bantam                       9170\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in Image-URL-S are 177887\n",
      "\n",
      "Some unique values in the Image-URL-S column:\n",
      "['http://images.amazon.com/images/P/002542730X.01.THUMBZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/0026217457.01.THUMBZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/003008685X.01.THUMBZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/0030615321.01.THUMBZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/0060002050.01.THUMBZZZ.jpg']\n",
      "\n",
      "Top 10 Sample of the Distribution of the Image-URL-S column\n",
      "Image-URL-S\n",
      "http://images.amazon.com/images/P/0971880107.01.THUMBZZZ.jpg    363\n",
      "http://images.amazon.com/images/P/0316666343.01.THUMBZZZ.jpg    270\n",
      "http://images.amazon.com/images/P/0060928336.01.THUMBZZZ.jpg    220\n",
      "http://images.amazon.com/images/P/0440214041.01.THUMBZZZ.jpg    218\n",
      "http://images.amazon.com/images/P/0385504209.01.THUMBZZZ.jpg    215\n",
      "http://images.amazon.com/images/P/044021145X.01.THUMBZZZ.jpg    206\n",
      "http://images.amazon.com/images/P/0440211727.01.THUMBZZZ.jpg    203\n",
      "http://images.amazon.com/images/P/067976402X.01.THUMBZZZ.jpg    194\n",
      "http://images.amazon.com/images/P/0440222656.01.THUMBZZZ.jpg    183\n",
      "http://images.amazon.com/images/P/059035342X.01.THUMBZZZ.jpg    183\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in Image-URL-M are 177887\n",
      "\n",
      "Some unique values in the Image-URL-M column:\n",
      "['http://images.amazon.com/images/P/002542730X.01.MZZZZZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/0026217457.01.MZZZZZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/003008685X.01.MZZZZZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/0030615321.01.MZZZZZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/0060002050.01.MZZZZZZZ.jpg']\n",
      "\n",
      "Top 10 Sample of the Distribution of the Image-URL-M column\n",
      "Image-URL-M\n",
      "http://images.amazon.com/images/P/0971880107.01.MZZZZZZZ.jpg    363\n",
      "http://images.amazon.com/images/P/0316666343.01.MZZZZZZZ.jpg    270\n",
      "http://images.amazon.com/images/P/0060928336.01.MZZZZZZZ.jpg    220\n",
      "http://images.amazon.com/images/P/0440214041.01.MZZZZZZZ.jpg    218\n",
      "http://images.amazon.com/images/P/0385504209.01.MZZZZZZZ.jpg    215\n",
      "http://images.amazon.com/images/P/044021145X.01.MZZZZZZZ.jpg    206\n",
      "http://images.amazon.com/images/P/0440211727.01.MZZZZZZZ.jpg    203\n",
      "http://images.amazon.com/images/P/067976402X.01.MZZZZZZZ.jpg    194\n",
      "http://images.amazon.com/images/P/0440222656.01.MZZZZZZZ.jpg    183\n",
      "http://images.amazon.com/images/P/059035342X.01.MZZZZZZZ.jpg    183\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in img_url are 177887\n",
      "\n",
      "Some unique values in the img_url column:\n",
      "['http://images.amazon.com/images/P/002542730X.01.LZZZZZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/0026217457.01.LZZZZZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/003008685X.01.LZZZZZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/0030615321.01.LZZZZZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/0060002050.01.LZZZZZZZ.jpg']\n",
      "\n",
      "Top 10 Sample of the Distribution of the img_url column\n",
      "img_url\n",
      "http://images.amazon.com/images/P/0971880107.01.LZZZZZZZ.jpg    363\n",
      "http://images.amazon.com/images/P/0316666343.01.LZZZZZZZ.jpg    270\n",
      "http://images.amazon.com/images/P/0060928336.01.LZZZZZZZ.jpg    220\n",
      "http://images.amazon.com/images/P/0440214041.01.LZZZZZZZ.jpg    218\n",
      "http://images.amazon.com/images/P/0385504209.01.LZZZZZZZ.jpg    215\n",
      "http://images.amazon.com/images/P/044021145X.01.LZZZZZZZ.jpg    206\n",
      "http://images.amazon.com/images/P/0440211727.01.LZZZZZZZ.jpg    203\n",
      "http://images.amazon.com/images/P/067976402X.01.LZZZZZZZ.jpg    194\n",
      "http://images.amazon.com/images/P/0440222656.01.LZZZZZZZ.jpg    183\n",
      "http://images.amazon.com/images/P/059035342X.01.LZZZZZZZ.jpg    183\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "COLUMNS\n",
      "\n",
      "The Numerical Features are:\n",
      "['user_id', 'rating']\n",
      "\n",
      "The Categorical Features are:\n",
      "['ISBN', 'title', 'author', 'year', 'publisher', 'Image-URL-S', 'Image-URL-M', 'img_url']\n"
     ]
    }
   ],
   "source": [
    "# Understanding the new data\n",
    "merged_rating_books = DataUnderstading('Merged Ratings and Books', df=ratings_with_books)\n",
    "merged_rating_books.understanding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many ratings does each book have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156308</th>\n",
       "      <td>Wild Animus</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19139</th>\n",
       "      <td>Bridget Jones's Diary</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130220</th>\n",
       "      <td>The Lovely Bones: A Novel</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132887</th>\n",
       "      <td>The Notebook</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133894</th>\n",
       "      <td>The Pelican Brief</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93079</th>\n",
       "      <td>Portrait sÃ?Â©pia</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93078</th>\n",
       "      <td>Portrait of the Theatre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93077</th>\n",
       "      <td>Portrait of the Psychopath as a Young Woman</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38036</th>\n",
       "      <td>Edge of Violence</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160263</th>\n",
       "      <td>Ã?Â?thique en toc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160264 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title  rating\n",
       "156308                                  Wild Animus     363\n",
       "19139                         Bridget Jones's Diary     277\n",
       "130220                    The Lovely Bones: A Novel     270\n",
       "132887                                 The Notebook     241\n",
       "133894                            The Pelican Brief     236\n",
       "...                                             ...     ...\n",
       "93079                             Portrait sÃ?Â©pia       1\n",
       "93078                       Portrait of the Theatre       1\n",
       "93077   Portrait of the Psychopath as a Young Woman       1\n",
       "38036                              Edge of Violence       1\n",
       "160263                            Ã?Â?thique en toc       1\n",
       "\n",
       "[160264 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rating = ratings_with_books.groupby('title')['rating'].count().reset_index()\n",
    "num_rating.sort_values(by='rating', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations\n",
    "> There are some books that received less than 50 reviews. We should only focus on books with many reviews.\n",
    "> Books with 1 rating would only not be sufficient enough to judge whether it was a good book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the columns\n",
    "num_rating.rename(columns={\n",
    "    'rating': \"no_of_rating\"\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging the data - `ratings_with_books` with `num_ratings` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching column between the ratings with books and num of ratings is\n",
      "title\n"
     ]
    }
   ],
   "source": [
    "# Check for similar columns\n",
    "similar_cols(ratings_with_books, \"ratings with books\", num_rating, 'num of ratings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Datasets on 'title'\n",
    "final_rating = ratings_with_books.merge(num_rating, on='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep the books with more than or equal to ratings by users\n",
    "final_rating = final_rating[final_rating['no_of_rating'] >= 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA UNDERSTANDING OF THE Final Rating Dataset\n",
      "\n",
      "\n",
      "SHAPE\n",
      "The Final Rating dataset contains 61,853 records and 11 columns\n",
      "The columns are ['ISBN', 'Image-URL-M', 'Image-URL-S', 'author', 'img_url', 'no_of_rating', 'publisher', 'rating', 'title', 'user_id', 'year']\n",
      "\n",
      "\n",
      "MISSING VALUES\n",
      "\n",
      "Missing values in the Final Rating dataset:\n",
      "0\n",
      "\n",
      "\n",
      "DUPLICATES\n",
      "\n",
      "Duplicate values in the Final Rating dataset:\n",
      "0\n",
      "\n",
      "\n",
      "DATATYPES\n",
      "\n",
      "Number of Features with [dtype('int64'), dtype('O')] datatypes are [3, 8] respectively\n",
      "\n",
      "\n",
      "UNIQUE VALUES\n",
      "\n",
      "Number of unique values in user_id are 888\n",
      "\n",
      "Some unique values in the user_id column:\n",
      "[277427   3363  11676  12538  13552]\n",
      "\n",
      "Top 10 Sample of the Distribution of the user_id column\n",
      "user_id\n",
      "11676     989\n",
      "35859     451\n",
      "76352     400\n",
      "16795     388\n",
      "153662    369\n",
      "102967    337\n",
      "230522    329\n",
      "185233    320\n",
      "78783     317\n",
      "55492     311\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in ISBN are 2249\n",
      "\n",
      "Some unique values in the ISBN column:\n",
      "['002542730X' '002542730x' '0060930535' '0060934417' '0061009059']\n",
      "\n",
      "Top 10 Sample of the Distribution of the ISBN column\n",
      "ISBN\n",
      "0971880107    363\n",
      "0316666343    270\n",
      "0060928336    220\n",
      "0440214041    218\n",
      "0385504209    215\n",
      "044021145X    204\n",
      "0440211727    203\n",
      "067976402X    193\n",
      "0440222656    183\n",
      "059035342X    183\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in rating are 11\n",
      "\n",
      "Some unique values in the rating column:\n",
      "[10  0  6  7  5  8  9  4  3  1  2]\n",
      "\n",
      "Top 10 Sample of the Distribution of the rating column\n",
      "rating\n",
      "0     46253\n",
      "8      3804\n",
      "10     3506\n",
      "9      3104\n",
      "7      2325\n",
      "5      1441\n",
      "6       968\n",
      "4       207\n",
      "3       113\n",
      "2        67\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in title are 742\n",
      "\n",
      "Some unique values in the title column:\n",
      "['Politically Correct Bedtime Stories: Modern Tales for Our Life and Times'\n",
      " 'The Poisonwood Bible: A Novel' 'Bel Canto: A Novel'\n",
      " 'One for the Money (Stephanie Plum Novels (Paperback))'\n",
      " 'The Secret Garden']\n",
      "\n",
      "Top 10 Sample of the Distribution of the title column\n",
      "title\n",
      "Wild Animus                                        363\n",
      "Bridget Jones's Diary                              277\n",
      "The Lovely Bones: A Novel                          270\n",
      "The Notebook                                       241\n",
      "The Pelican Brief                                  236\n",
      "The Nanny Diaries: A Novel                         230\n",
      "Divine Secrets of the Ya-Ya Sisterhood: A Novel    228\n",
      "A Painted House                                    228\n",
      "The Firm                                           227\n",
      "The Da Vinci Code                                  224\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in author are 599\n",
      "\n",
      "Some unique values in the author column:\n",
      "['James Finn Garner' 'Barbara Kingsolver' 'Ann Patchett' 'Janet Evanovich'\n",
      " 'Frances Hodgson Burnett']\n",
      "\n",
      "Top 10 Sample of the Distribution of the author column\n",
      "author\n",
      "Stephen King                 2579\n",
      "Nora Roberts                 2302\n",
      "John Grisham                 1820\n",
      "James Patterson              1751\n",
      "Mary Higgins Clark           1361\n",
      "Sue Grafton                  1290\n",
      "Janet Evanovich              1177\n",
      "Dean R. Koontz               1170\n",
      "Patricia Daniels Cornwell     958\n",
      "Nicholas Sparks               944\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in year are 47\n",
      "\n",
      "Some unique values in the year column:\n",
      "['1994' '1999' '2002' '1995' '1998']\n",
      "\n",
      "Top 10 Sample of the Distribution of the year column\n",
      "year\n",
      "2002    7405\n",
      "1999    6116\n",
      "2001    5503\n",
      "2000    4607\n",
      "1998    4485\n",
      "2003    4474\n",
      "1996    4036\n",
      "1997    3727\n",
      "1994    3095\n",
      "1995    2942\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in publisher are 376\n",
      "\n",
      "Some unique values in the publisher column:\n",
      "['John Wiley &amp; Sons Inc' 'Perennial' 'HarperTorch' 'HarperTrophy'\n",
      " 'Laure Leaf']\n",
      "\n",
      "Top 10 Sample of the Distribution of the publisher column\n",
      "publisher\n",
      "Ballantine Books            4545\n",
      "Berkley Publishing Group    4031\n",
      "Warner Books                3640\n",
      "Pocket                      3336\n",
      "Dell                        3003\n",
      "Bantam                      2362\n",
      "Bantam Books                1924\n",
      "Dell Publishing Company     1837\n",
      "Signet Book                 1811\n",
      "Jove Books                  1737\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in Image-URL-S are 2226\n",
      "\n",
      "Some unique values in the Image-URL-S column:\n",
      "['http://images.amazon.com/images/P/002542730X.01.THUMBZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/0060930535.01.THUMBZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/0060934417.01.THUMBZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/0061009059.01.THUMBZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/006440188X.01.THUMBZZZ.jpg']\n",
      "\n",
      "Top 10 Sample of the Distribution of the Image-URL-S column\n",
      "Image-URL-S\n",
      "http://images.amazon.com/images/P/0971880107.01.THUMBZZZ.jpg    363\n",
      "http://images.amazon.com/images/P/0316666343.01.THUMBZZZ.jpg    270\n",
      "http://images.amazon.com/images/P/0060928336.01.THUMBZZZ.jpg    220\n",
      "http://images.amazon.com/images/P/0440214041.01.THUMBZZZ.jpg    218\n",
      "http://images.amazon.com/images/P/0385504209.01.THUMBZZZ.jpg    215\n",
      "http://images.amazon.com/images/P/044021145X.01.THUMBZZZ.jpg    206\n",
      "http://images.amazon.com/images/P/0440211727.01.THUMBZZZ.jpg    203\n",
      "http://images.amazon.com/images/P/067976402X.01.THUMBZZZ.jpg    194\n",
      "http://images.amazon.com/images/P/0446672211.01.THUMBZZZ.jpg    183\n",
      "http://images.amazon.com/images/P/0440222656.01.THUMBZZZ.jpg    183\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in Image-URL-M are 2226\n",
      "\n",
      "Some unique values in the Image-URL-M column:\n",
      "['http://images.amazon.com/images/P/002542730X.01.MZZZZZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/0060930535.01.MZZZZZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/0060934417.01.MZZZZZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/0061009059.01.MZZZZZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/006440188X.01.MZZZZZZZ.jpg']\n",
      "\n",
      "Top 10 Sample of the Distribution of the Image-URL-M column\n",
      "Image-URL-M\n",
      "http://images.amazon.com/images/P/0971880107.01.MZZZZZZZ.jpg    363\n",
      "http://images.amazon.com/images/P/0316666343.01.MZZZZZZZ.jpg    270\n",
      "http://images.amazon.com/images/P/0060928336.01.MZZZZZZZ.jpg    220\n",
      "http://images.amazon.com/images/P/0440214041.01.MZZZZZZZ.jpg    218\n",
      "http://images.amazon.com/images/P/0385504209.01.MZZZZZZZ.jpg    215\n",
      "http://images.amazon.com/images/P/044021145X.01.MZZZZZZZ.jpg    206\n",
      "http://images.amazon.com/images/P/0440211727.01.MZZZZZZZ.jpg    203\n",
      "http://images.amazon.com/images/P/067976402X.01.MZZZZZZZ.jpg    194\n",
      "http://images.amazon.com/images/P/0446672211.01.MZZZZZZZ.jpg    183\n",
      "http://images.amazon.com/images/P/0440222656.01.MZZZZZZZ.jpg    183\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in img_url are 2226\n",
      "\n",
      "Some unique values in the img_url column:\n",
      "['http://images.amazon.com/images/P/002542730X.01.LZZZZZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/0060930535.01.LZZZZZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/0060934417.01.LZZZZZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/0061009059.01.LZZZZZZZ.jpg'\n",
      " 'http://images.amazon.com/images/P/006440188X.01.LZZZZZZZ.jpg']\n",
      "\n",
      "Top 10 Sample of the Distribution of the img_url column\n",
      "img_url\n",
      "http://images.amazon.com/images/P/0971880107.01.LZZZZZZZ.jpg    363\n",
      "http://images.amazon.com/images/P/0316666343.01.LZZZZZZZ.jpg    270\n",
      "http://images.amazon.com/images/P/0060928336.01.LZZZZZZZ.jpg    220\n",
      "http://images.amazon.com/images/P/0440214041.01.LZZZZZZZ.jpg    218\n",
      "http://images.amazon.com/images/P/0385504209.01.LZZZZZZZ.jpg    215\n",
      "http://images.amazon.com/images/P/044021145X.01.LZZZZZZZ.jpg    206\n",
      "http://images.amazon.com/images/P/0440211727.01.LZZZZZZZ.jpg    203\n",
      "http://images.amazon.com/images/P/067976402X.01.LZZZZZZZ.jpg    194\n",
      "http://images.amazon.com/images/P/0446672211.01.LZZZZZZZ.jpg    183\n",
      "http://images.amazon.com/images/P/0440222656.01.LZZZZZZZ.jpg    183\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique values in no_of_rating are 130\n",
      "\n",
      "Some unique values in the no_of_rating column:\n",
      "[ 82 133 108  79  77]\n",
      "\n",
      "Top 10 Sample of the Distribution of the no_of_rating column\n",
      "no_of_rating\n",
      "50    1950\n",
      "53    1696\n",
      "62    1302\n",
      "59    1239\n",
      "68    1156\n",
      "52    1144\n",
      "81    1134\n",
      "56    1120\n",
      "84    1092\n",
      "78    1092\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "COLUMNS\n",
      "\n",
      "The Numerical Features are:\n",
      "['user_id', 'rating', 'no_of_rating']\n",
      "\n",
      "The Categorical Features are:\n",
      "['ISBN', 'title', 'author', 'year', 'publisher', 'Image-URL-S', 'Image-URL-M', 'img_url']\n"
     ]
    }
   ],
   "source": [
    "complete_rating = DataUnderstading('Final Rating', final_rating)\n",
    "complete_rating.understanding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a pivot table off the final_rating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>user_id</th>\n",
       "      <th>254</th>\n",
       "      <th>2276</th>\n",
       "      <th>2766</th>\n",
       "      <th>2977</th>\n",
       "      <th>3363</th>\n",
       "      <th>3757</th>\n",
       "      <th>4017</th>\n",
       "      <th>4385</th>\n",
       "      <th>6242</th>\n",
       "      <th>6251</th>\n",
       "      <th>...</th>\n",
       "      <th>274004</th>\n",
       "      <th>274061</th>\n",
       "      <th>274301</th>\n",
       "      <th>274308</th>\n",
       "      <th>274808</th>\n",
       "      <th>275970</th>\n",
       "      <th>277427</th>\n",
       "      <th>277478</th>\n",
       "      <th>277639</th>\n",
       "      <th>278418</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st to Die: A Novel</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd Chance</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 Blondes</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84 Charing Cross Road</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year of Wonders</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You Belong To Me</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zen and the Art of Motorcycle Maintenance: An Inquiry into Values</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zoya</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\O\\\" Is for Outlaw\"</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>742 rows × 888 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "user_id                                             254     2276    2766    \\\n",
       "title                                                                        \n",
       "1984                                                   9.0     0.0     0.0   \n",
       "1st to Die: A Novel                                    0.0     0.0     0.0   \n",
       "2nd Chance                                             0.0    10.0     0.0   \n",
       "4 Blondes                                              0.0     0.0     0.0   \n",
       "84 Charing Cross Road                                  0.0     0.0     0.0   \n",
       "...                                                    ...     ...     ...   \n",
       "Year of Wonders                                        0.0     0.0     0.0   \n",
       "You Belong To Me                                       0.0     0.0     0.0   \n",
       "Zen and the Art of Motorcycle Maintenance: An I...     0.0     0.0     0.0   \n",
       "Zoya                                                   0.0     0.0     0.0   \n",
       "\\O\\\" Is for Outlaw\"                                    0.0     0.0     0.0   \n",
       "\n",
       "user_id                                             2977    3363    3757    \\\n",
       "title                                                                        \n",
       "1984                                                   0.0     0.0     0.0   \n",
       "1st to Die: A Novel                                    0.0     0.0     0.0   \n",
       "2nd Chance                                             0.0     0.0     0.0   \n",
       "4 Blondes                                              0.0     0.0     0.0   \n",
       "84 Charing Cross Road                                  0.0     0.0     0.0   \n",
       "...                                                    ...     ...     ...   \n",
       "Year of Wonders                                        7.0     0.0     0.0   \n",
       "You Belong To Me                                       0.0     0.0     0.0   \n",
       "Zen and the Art of Motorcycle Maintenance: An I...     0.0     0.0     0.0   \n",
       "Zoya                                                   0.0     0.0     0.0   \n",
       "\\O\\\" Is for Outlaw\"                                    0.0     0.0     0.0   \n",
       "\n",
       "user_id                                             4017    4385    6242    \\\n",
       "title                                                                        \n",
       "1984                                                   0.0     0.0     0.0   \n",
       "1st to Die: A Novel                                    0.0     0.0     0.0   \n",
       "2nd Chance                                             0.0     0.0     0.0   \n",
       "4 Blondes                                              0.0     0.0     0.0   \n",
       "84 Charing Cross Road                                  0.0     0.0     0.0   \n",
       "...                                                    ...     ...     ...   \n",
       "Year of Wonders                                        0.0     0.0     7.0   \n",
       "You Belong To Me                                       0.0     0.0     0.0   \n",
       "Zen and the Art of Motorcycle Maintenance: An I...     0.0     0.0     0.0   \n",
       "Zoya                                                   0.0     0.0     0.0   \n",
       "\\O\\\" Is for Outlaw\"                                    0.0     0.0     0.0   \n",
       "\n",
       "user_id                                             6251    ...  274004  \\\n",
       "title                                                       ...           \n",
       "1984                                                   0.0  ...     0.0   \n",
       "1st to Die: A Novel                                    0.0  ...     0.0   \n",
       "2nd Chance                                             0.0  ...     0.0   \n",
       "4 Blondes                                              0.0  ...     0.0   \n",
       "84 Charing Cross Road                                  0.0  ...     0.0   \n",
       "...                                                    ...  ...     ...   \n",
       "Year of Wonders                                        0.0  ...     0.0   \n",
       "You Belong To Me                                       0.0  ...     0.0   \n",
       "Zen and the Art of Motorcycle Maintenance: An I...     0.0  ...     0.0   \n",
       "Zoya                                                   0.0  ...     0.0   \n",
       "\\O\\\" Is for Outlaw\"                                    0.0  ...     0.0   \n",
       "\n",
       "user_id                                             274061  274301  274308  \\\n",
       "title                                                                        \n",
       "1984                                                   0.0     0.0     0.0   \n",
       "1st to Die: A Novel                                    0.0     0.0     0.0   \n",
       "2nd Chance                                             0.0     0.0     0.0   \n",
       "4 Blondes                                              0.0     0.0     0.0   \n",
       "84 Charing Cross Road                                  0.0     0.0     0.0   \n",
       "...                                                    ...     ...     ...   \n",
       "Year of Wonders                                        0.0     0.0     0.0   \n",
       "You Belong To Me                                       0.0     0.0     0.0   \n",
       "Zen and the Art of Motorcycle Maintenance: An I...     0.0     0.0     0.0   \n",
       "Zoya                                                   0.0     0.0     0.0   \n",
       "\\O\\\" Is for Outlaw\"                                    0.0     8.0     0.0   \n",
       "\n",
       "user_id                                             274808  275970  277427  \\\n",
       "title                                                                        \n",
       "1984                                                   0.0     0.0     0.0   \n",
       "1st to Die: A Novel                                    0.0     0.0     0.0   \n",
       "2nd Chance                                             0.0     0.0     0.0   \n",
       "4 Blondes                                              0.0     0.0     0.0   \n",
       "84 Charing Cross Road                                  0.0    10.0     0.0   \n",
       "...                                                    ...     ...     ...   \n",
       "Year of Wonders                                        0.0     0.0     0.0   \n",
       "You Belong To Me                                       0.0     0.0     0.0   \n",
       "Zen and the Art of Motorcycle Maintenance: An I...     0.0     0.0     0.0   \n",
       "Zoya                                                   0.0     0.0     0.0   \n",
       "\\O\\\" Is for Outlaw\"                                    0.0     0.0     0.0   \n",
       "\n",
       "user_id                                             277478  277639  278418  \n",
       "title                                                                       \n",
       "1984                                                   0.0     0.0     0.0  \n",
       "1st to Die: A Novel                                    0.0     0.0     0.0  \n",
       "2nd Chance                                             0.0     0.0     0.0  \n",
       "4 Blondes                                              0.0     0.0     0.0  \n",
       "84 Charing Cross Road                                  0.0     0.0     0.0  \n",
       "...                                                    ...     ...     ...  \n",
       "Year of Wonders                                        0.0     0.0     0.0  \n",
       "You Belong To Me                                       0.0     0.0     0.0  \n",
       "Zen and the Art of Motorcycle Maintenance: An I...     0.0     0.0     0.0  \n",
       "Zoya                                                   0.0     0.0     0.0  \n",
       "\\O\\\" Is for Outlaw\"                                    0.0     0.0     0.0  \n",
       "\n",
       "[742 rows x 888 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivot Table\n",
    "book_pivot = final_rating.pivot_table(index='title', columns='user_id', values='rating')\n",
    "\n",
    "# Cleaning the NaN values\n",
    "book_pivot.fillna(value=0, inplace=True)\n",
    "\n",
    "# Visualise\n",
    "book_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_sparse = csr_matrix(book_pivot)\n",
    "\n",
    "# Confirming sparse matrix was created\n",
    "type(book_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a pivot table based on the authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id           254     2276    2766    2977    3363    3757    4017    \\\n",
      "author                                                                     \n",
      "A. Manette Ansay     0.0     0.0     0.0     0.0     0.0     0.0     9.0   \n",
      "A.S. BYATT           0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "user_id           4385    6242    6251    ...  274004  274061  274301  274308  \\\n",
      "author                                    ...                                   \n",
      "A. Manette Ansay     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0   \n",
      "A.S. BYATT           0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0   \n",
      "\n",
      "user_id           274808  275970  277427  277478  277639  278418  \n",
      "author                                                            \n",
      "A. Manette Ansay     0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "A.S. BYATT           0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "\n",
      "[2 rows x 888 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "599"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivot Table\n",
    "author_pivot = final_rating.pivot_table(index='author', columns='user_id', values='rating')\n",
    "\n",
    "# Cleaning the NaN values\n",
    "author_pivot.fillna(value=0, inplace=True)\n",
    "\n",
    "# Visualise\n",
    "print(author_pivot.head(2))\n",
    "\n",
    "# Create a sparse matrix\n",
    "author_sparse = csr_matrix(author_pivot)\n",
    "\n",
    "# Confirmation\n",
    "type(author_sparse)\n",
    "\n",
    "# Length\n",
    "len(author_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Charlotte Lamb', 'Harry Potter and the Chamber of Secrets (Book 2)')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_pivot.iloc[100,:].name, book_pivot.iloc[237,:].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbors Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiation\n",
    "model = NearestNeighbors(algorithm='brute')\n",
    "\n",
    "# Fitting\n",
    "model.fit(book_sparse)\n",
    "\n",
    "# Prediction\n",
    "test_record = book_pivot.iloc[237, :].values.reshape(1, -1)\n",
    "distance, suggestion = model.kneighbors(test_record, n_neighbors=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , 67.73129098, 67.77802823, 72.22091879, 76.03909813,\n",
       "        76.55027397]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the distance\n",
    "distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations\n",
    "> The first item is 0 meaning the model is comparing the datapoint `test_record` with itself. \n",
    "> The rest of the values are the 6 closest distances available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Harry Potter and the Chamber of Secrets (Book 2)',\n",
      "       'Harry Potter and the Prisoner of Azkaban (Book 3)',\n",
      "       'Harry Potter and the Goblet of Fire (Book 4)',\n",
      "       'Harry Potter and the Sorcerer's Stone (Book 1)', 'Exclusive',\n",
      "       'Jacob Have I Loved'],\n",
      "      dtype='object', name='title')\n"
     ]
    }
   ],
   "source": [
    "# The suggested indexes\n",
    "suggestion # array([[237, 240, 238, 241, 184, 291]], dtype=int64)\n",
    "\n",
    "# Book values\n",
    "for idx in suggestion:\n",
    "    print(book_pivot.index[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelling for the Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10 284 155 558 303 505]]\n",
      "Index(['Aldous Huxley', 'Jerome David Salinger', 'Dorothy West',\n",
      "       'Talmadge-Bickmore Deborah', 'Jonathan Harr', 'Robert K. Massie'],\n",
      "      dtype='object', name='author')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , 36.10747845, 36.49315004, 36.58893275, 37.27935085,\n",
       "        37.27935085]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiation\n",
    "author_model = NearestNeighbors(algorithm='brute')\n",
    "\n",
    "# Fit\n",
    "author_model.fit(author_sparse)\n",
    "\n",
    "# Test Record\n",
    "test_record = author_pivot.iloc[10, :].values.reshape(1, -1)\n",
    "\n",
    "# Prediction\n",
    "distance, suggestion = author_model.kneighbors(test_record, n_neighbors=6)\n",
    "\n",
    "print(suggestion)\n",
    "\n",
    "# Authors\n",
    "for idx in suggestion:\n",
    "    print(author_pivot.index[idx])\n",
    "    \n",
    "# Distance\n",
    "distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the book names \n",
    "book_names = book_pivot.index\n",
    "\n",
    "# Save all the author names\n",
    "author_names = author_pivot.index\n",
    "\n",
    "# Store the models in a pickle\n",
    "pickle.dump(model, open('models/book_model.pkl', 'wb'))\n",
    "pickle.dump(author_model, open('models/author_model.pkl', 'wb'))\n",
    "\n",
    "# Save the names of the books\n",
    "pickle.dump(book_names, open('models/book_names.pkl', 'wb'))\n",
    "pickle.dump(author_names, open('models/author_names.pkl', 'wb'))\n",
    "\n",
    "# Save the final ratings df\n",
    "pickle.dump(final_rating, open('models/final_rating.pkl', 'wb'))\n",
    "\n",
    "# Save the names of the books\n",
    "pickle.dump(book_pivot, open('models/book_pivot.pkl', 'wb'))\n",
    "pickle.dump(author_pivot, open('models/author_pivot.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation\n",
    "\n",
    "### Testing the recommendation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_details(book_title):\n",
    "    return final_rating[final_rating['title'] == book_title].sort_values(by='year', ascending=False)\\\n",
    "            .iloc[0,:][['ISBN', 'author', 'img_url']]\n",
    "\n",
    "def get_top_author_books(author):\n",
    "    books =  final_rating[final_rating['author'] == author]\\\n",
    "                .sort_values(by='rating', ascending=False).iloc[:5,3].values\n",
    "    \n",
    "    for j in books:\n",
    "        print(j)\n",
    "    \n",
    "\n",
    "# Book Recommender Function\n",
    "def recommend_book(book_name):\n",
    "    \"\"\"This function takes in a book name and returns 6 suggestions\"\"\"\n",
    "    # Get the book id from the book pivot table \n",
    "    book_id = np.where(book_pivot.index == book_name)[0][0]\n",
    "    \n",
    "    # Get the row of records from the book id\n",
    "    record = book_pivot.iloc[book_id, :].values.reshape(1, -1)\n",
    "    \n",
    "    # Get the distance and suggestion from the book model\n",
    "    distance, suggestion = model.kneighbors(record, n_neighbors=6)\n",
    "    \n",
    "    # Get all the books from the suggestion\n",
    "    for idx in range(len(suggestion)):\n",
    "        \n",
    "        # Returns a list of type index\n",
    "        books = book_pivot.index[suggestion[idx]]\n",
    "        \n",
    "        # Returns each individual item in the list\n",
    "        for j in books:\n",
    "            print(j)\n",
    "            print(\"Book Details\")\n",
    "            print(get_book_details(j))\n",
    "            print(\"\")\n",
    "            \n",
    "# Book Recommender Function\n",
    "def recommend_author(author_name):\n",
    "    \"\"\"This function takes in a book name and returns 6 suggestions\"\"\"\n",
    "    # Get the book id from the book pivot table \n",
    "    author_id = np.where(author_pivot.index == author_name)[0][0]\n",
    "    \n",
    "    # Get the row of records from the book id\n",
    "    record = author_pivot.iloc[author_id, :].values.reshape(1, -1)\n",
    "    \n",
    "    # Get the distance and suggestion from the book model\n",
    "    distance, suggestion = author_model.kneighbors(record, n_neighbors=6)\n",
    "    \n",
    "    # Get all the books from the suggestion\n",
    "    for idx in range(len(suggestion)):\n",
    "        \n",
    "        # Returns a list of type index\n",
    "        authors = author_pivot.index[suggestion[idx]]\n",
    "        \n",
    "        # Returns each individual item in the list\n",
    "        for j in authors:\n",
    "            print(j)\n",
    "            print(f'Highly rated books by {j} include')\n",
    "            get_top_author_books(j)\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacob Have I Loved\n",
      "Book Details\n",
      "ISBN                                              0064403688\n",
      "author                                    Katherine Paterson\n",
      "img_url    http://images.amazon.com/images/P/0064403688.0...\n",
      "Name: 103022, dtype: object\n",
      "\n",
      "Exclusive\n",
      "Book Details\n",
      "ISBN                                              0446604232\n",
      "author                                          Sandra Brown\n",
      "img_url    http://images.amazon.com/images/P/0446604232.0...\n",
      "Name: 96980, dtype: object\n",
      "\n",
      "No Safe Place\n",
      "Book Details\n",
      "ISBN                                              0345404777\n",
      "author                               RICHARD NORTH PATTERSON\n",
      "img_url    http://images.amazon.com/images/P/0345404777.0...\n",
      "Name: 3045, dtype: object\n",
      "\n",
      "Journey\n",
      "Book Details\n",
      "ISBN                                              0440237025\n",
      "author                                        Danielle Steel\n",
      "img_url    http://images.amazon.com/images/P/0440237025.0...\n",
      "Name: 164208, dtype: object\n",
      "\n",
      "The Cradle Will Fall\n",
      "Book Details\n",
      "ISBN                                              0671741195\n",
      "author                                    Mary Higgins Clark\n",
      "img_url    http://images.amazon.com/images/P/0671741195.0...\n",
      "Name: 169696, dtype: object\n",
      "\n",
      "Long After Midnight\n",
      "Book Details\n",
      "ISBN                                              0671037692\n",
      "author                                          Ray Bradbury\n",
      "img_url    http://images.amazon.com/images/P/0671037692.0...\n",
      "Name: 10632, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "recommend_book('Jacob Have I Loved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary Higgins Clark\n",
      "Highly rated books by Mary Higgins Clark include\n",
      "All Around the Town\n",
      "Pretend You Don't See Her\n",
      "Stillwatch\n",
      "Let Me Call You Sweetheart\n",
      "We'll Meet Again\n",
      "\n",
      "Jennifer Lauck\n",
      "Highly rated books by Jennifer Lauck include\n",
      "Still Waters\n",
      "Still Waters\n",
      "Still Waters\n",
      "Still Waters\n",
      "Still Waters\n",
      "\n",
      "Golden Books\n",
      "Highly rated books by Golden Books include\n",
      "Jurassic Park\n",
      "\n",
      "Lisa Jackson\n",
      "Highly rated books by Lisa Jackson include\n",
      "Whispers\n",
      "Whispers\n",
      "Whispers\n",
      "Whispers\n",
      "Whispers\n",
      "\n",
      "Debra Dier\n",
      "Highly rated books by Debra Dier include\n",
      "Dangerous\n",
      "Dangerous\n",
      "Dangerous\n",
      "\n",
      "Sharon K. Garner\n",
      "Highly rated books by Sharon K. Garner include\n",
      "Sanctuary\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommend_author(\"Mary Higgins Clark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Around the Town\n",
      "Pretend You Don't See Her\n",
      "Stillwatch\n",
      "Let Me Call You Sweetheart\n",
      "We'll Meet Again\n"
     ]
    }
   ],
   "source": [
    "get_top_author_books('Mary Higgins Clark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ISBN                                              0785700099\n",
       "author                                    Mary Higgins Clark\n",
       "img_url    http://images.amazon.com/images/P/0785700099.0...\n",
       "Name: 97968, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_book_details(\"All Around the Town\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ISBN                                              0064403688\n",
       "author                                    Katherine Paterson\n",
       "img_url    http://images.amazon.com/images/P/0064403688.0...\n",
       "Name: 103022, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rating[final_rating['title'] == 'Jacob Have I Loved'].sort_values(by='year', ascending=False).iloc[0,:][['ISBN', 'author', 'img_url']]\n",
    "final_rating[final_rating['author'] == 'Mary Higgins Clark'].sort_values(by='rating', ascending=False).iloc[:5,3].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
